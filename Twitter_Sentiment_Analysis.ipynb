{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twitter Sentiment Analysis using NLP\n",
        "### Thesis Project \u2014 Sentiment140 Dataset\n",
        "\n",
        "This notebook performs sentiment analysis on Twitter data using the Sentiment140 dataset.\n",
        "It includes data preprocessing, TF-IDF feature extraction, Logistic Regression model training, evaluation, and visualization.\n",
        "\n",
        "**Author:** Your Name  \n",
        "**Date:** 2025-11-08"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install --quiet pandas numpy scikit-learn nltk matplotlib seaborn wordcloud joblib kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, string, os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "import joblib\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "colnames = ['target', 'id', 'date', 'query', 'user', 'text']\n",
        "csv_path = 'data/sentiment140.csv'\n",
        "df = pd.read_csv(csv_path, encoding='latin-1', names=colnames)\n",
        "df['label'] = df['target'].apply(lambda x: 1 if x == 4 else 0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "mention_pattern = re.compile(r'@\\w+')\n",
        "rt_pattern = re.compile(r'\\brt\\b')\n",
        "hashtag_pattern = re.compile(r'#')\n",
        "\n",
        "def clean_tweet(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = url_pattern.sub('', text)\n",
        "    text = mention_pattern.sub('', text)\n",
        "    text = rt_pattern.sub('', text)\n",
        "    text = hashtag_pattern.sub('', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and len(t) > 1]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['clean_text'] = df['text'].astype(str).apply(clean_tweet)\n",
        "df[['text', 'clean_text']].head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = df['clean_text']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2), min_df=5, max_df=0.9, sublinear_tf=True)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(solver='saga', penalty='l2', C=1.0, max_iter=200, n_jobs=-1, class_weight='balanced', random_state=42)\n",
        "clf.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall:', recall_score(y_test, y_pred))\n",
        "print('F1:', f1_score(y_test, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['neg','pos'], yticklabels=['neg','pos'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "joblib.dump(clf, 'sentiment_model.joblib')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict_sentiment(text):\n",
        "    clean = clean_tweet(text)\n",
        "    vec = vectorizer.transform([clean])\n",
        "    pred = clf.predict(vec)[0]\n",
        "    prob = clf.predict_proba(vec).max()\n",
        "    return 'Positive' if pred==1 else 'Negative', round(prob,3)\n",
        "\n",
        "samples = [\n",
        "    'I love this new phone!',\n",
        "    'Worst service ever!',\n",
        "    'It is okay, not great.'\n",
        "]\n",
        "\n",
        "for s in samples:\n",
        "    label, prob = predict_sentiment(s)\n",
        "    print(f'{s} \u2192 {label} ({prob})')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}